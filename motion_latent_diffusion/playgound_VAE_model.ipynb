{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENCODING\n",
      "batch size: 16 nframes: 420 nfeats: 66\n",
      "skel_enc: torch.Size([16, 420, 256])\n",
      "skip trans enc: torch.Size([16, 420, 256])\n",
      "conv2d: torch.Size([16, 32, 69, 1])\n",
      "flattened: torch.Size([16, 2208])\n",
      "final linear: torch.Size([16, 512])\n",
      "latent: torch.Size([16, 256])\n",
      "latentdim: tensor(256)\n",
      "DECODING\n",
      "batch size: 16 nframes: 420 z shape: torch.Size([16, 256])\n",
      "linear: torch.Size([16, 2208])\n",
      "linear: torch.Size([16, 1, 69, 32])\n",
      "transconv1d: torch.Size([16, 7, 420, 39])\n",
      "linear: torch.Size([16, 420, 256])\n",
      "skip trans dec2: torch.Size([16, 420, 256])\n",
      "final layer: torch.Size([16, 420, 66])\n",
      "feats: torch.Size([16, 420, 66])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from utils import (\n",
    "    plot_3d_motion_frames_multiple,\n",
    "    plot_3d_motion_animation,\n",
    "    plot_3d_motion_frames_multiple,\n",
    "    activation_dict,\n",
    ")\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from modules.loss import VAE_Loss\n",
    "\n",
    "from torch import Tensor\n",
    "from typing import List, Optional\n",
    "import copy\n",
    "\n",
    "def lengths_to_mask(lengths: List[int],\n",
    "                    device: torch.device,\n",
    "                    max_len: int = None) -> Tensor:\n",
    "    \"\"\"\n",
    "    Provides a mask, of length max_len or the longest element in lengths. With True for the elements less than the length for each length in lengths.\n",
    "    \"\"\"\n",
    "    lengths = torch.tensor(lengths, device=device)\n",
    "    max_len = max_len if max_len else max(lengths)\n",
    "    mask = torch.arange(max_len, device=device).expand(len(lengths), max_len) < lengths.unsqueeze(1)\n",
    "    return mask\n",
    "\n",
    "def _get_clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n",
    "\n",
    "def _get_clone(module):\n",
    "    return copy.deepcopy(module)\n",
    "\n",
    "class SkipTransformerEncoder(nn.Module):\n",
    "    def __init__(self, encoder_layer, num_layers, norm=None, d_model=256):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        self.norm = norm\n",
    "\n",
    "        assert num_layers % 2 == 1\n",
    "\n",
    "        num_block = (num_layers-1)//2\n",
    "        self.input_blocks = _get_clones(encoder_layer, num_block)\n",
    "        self.middle_block = _get_clone(encoder_layer)\n",
    "        self.output_blocks = _get_clones(encoder_layer, num_block)\n",
    "        self.linear_blocks = _get_clones(nn.Linear(2*self.d_model, self.d_model), num_block)\n",
    "\n",
    "        self._reset_parameters()\n",
    "\n",
    "    def _reset_parameters(self):\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "\n",
    "    def forward(self, src,\n",
    "                mask: Optional[Tensor] = None,\n",
    "                src_key_padding_mask: Optional[Tensor] = None,\n",
    "                pos: Optional[Tensor] = None):\n",
    "        x = src\n",
    "\n",
    "        xs = []\n",
    "        for module in self.input_blocks:\n",
    "            x = module(x, src_mask=mask,\n",
    "                           src_key_padding_mask=src_key_padding_mask)\n",
    "            xs.append(x)\n",
    "\n",
    "        x = self.middle_block(x, src_mask=mask,\n",
    "                           src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "        for (module, linear) in zip(self.output_blocks, self.linear_blocks):\n",
    "            x = torch.cat([x, xs.pop()], dim=-1)\n",
    "            x = linear(x)\n",
    "            x = module(x, src_mask=mask,\n",
    "                           src_key_padding_mask=src_key_padding_mask, \n",
    "                           )\n",
    "\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "        return x\n",
    "\n",
    "class CascadingTransformerAutoEncoder(nn.Module):\n",
    "    def __init__(self, d_model, nhead, num_layers, dim_feedforward=2048, dropout=0.1, activation='relu', seq_len=120, verbose=False):\n",
    "        super(CascadingTransformerAutoEncoder, self).__init__()\n",
    "        self.latent_size = 1   # 1 for single timestep\n",
    "        self.latent_dim = d_model # 256\n",
    "        self.seq_len = seq_len\n",
    "        self.verbose = verbose\n",
    "        self.conv1_out_channels = 32\n",
    "        self.activation = nn.LeakyReLU()\n",
    "        \n",
    "        # ENCODER\n",
    "        self.skel_enc = nn.Linear(66, d_model)\n",
    "    \n",
    "        self.skip_trans_enc = SkipTransformerEncoder(\n",
    "            encoder_layer= nn.TransformerEncoderLayer(\n",
    "                d_model=256, nhead=64, dim_feedforward=1024, \n",
    "                dropout=0.1, activation='gelu', \n",
    "                norm_first=False, batch_first=True),\n",
    "            num_layers=7,\n",
    "            norm=nn.LayerNorm(256),\n",
    "            d_model=256\n",
    "        )\n",
    "\n",
    "        self.conv2d_enc = nn.Conv2d(\n",
    "                            in_channels=1,\n",
    "                            out_channels=self.conv1_out_channels,\n",
    "                            kernel_size=(8, 256),\n",
    "                            stride=(6, 1),\n",
    "                            padding=(0, 0))\n",
    "        \n",
    "        self.enc_final_linear = nn.Sequential(\n",
    "            nn.Linear(2208, 512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "        )\n",
    "        # DECODER\n",
    "        self.linear_dec = nn.Sequential(\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(1024, 2208),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "\n",
    "        self.transconv2d_dec = nn.ConvTranspose2d(\n",
    "                            in_channels=1,\n",
    "                            out_channels=7,\n",
    "                            kernel_size=8,\n",
    "                            stride=(6,1),\n",
    "                            padding=(0,0), \n",
    "                            output_padding=(4,0))\n",
    "\n",
    "        self.linear_dec2 = nn.Sequential(\n",
    "            nn.Linear(273, 256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "        )\n",
    "        #nn.Linear(220, 256)\n",
    "\n",
    "        self.skip_trans_dec2 = SkipTransformerEncoder(\n",
    "            encoder_layer= nn.TransformerEncoderLayer(\n",
    "                d_model=256, nhead=64, dim_feedforward=1024,\n",
    "                dropout=0.1, activation='gelu',\n",
    "                norm_first=False, batch_first=True),\n",
    "            num_layers=7,\n",
    "            norm=nn.LayerNorm(256),\n",
    "            d_model=256\n",
    "        )\n",
    "        \n",
    "        self.final_layer = nn.Linear(256, 66)\n",
    "        \n",
    "    def forward(self, src: Tensor):\n",
    "        z, lengths, mu, logvar = self.encode(src)\n",
    "        # mu, logvar = dist[:1], dist[1:]\n",
    "        # z = self.reparameterize(mu, logvar)\n",
    "        output = self.decode(z, lengths)\n",
    "        return output, mu, logvar\n",
    "\n",
    "    def encode(self, src):\n",
    "        # get lengths\n",
    "        lengths = [len(feature) for feature in src]\n",
    "\n",
    "\n",
    "        if self.verbose: print('ENCODING')\n",
    "        # get shapes\n",
    "        bs, nframes, nfeats = src.shape\n",
    "        if self.verbose: print('batch size:', bs, 'nframes:', nframes, 'nfeats:', nfeats)\n",
    "\n",
    "        # skeletal embedding\n",
    "        x = self.skel_enc(src)\n",
    "        if self.verbose: print('skel_enc:', x.shape)\n",
    "\n",
    "        # pass through transformerencoder with skip connections\n",
    "        x = self.skip_trans_enc(x)\n",
    "        if self.verbose: print('skip trans enc:', x.shape)\n",
    "\n",
    "        # make small with conv2d\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.conv2d_enc(x)\n",
    "        x = self.activation(x)\n",
    "        if self.verbose: print('conv2d:', x.shape)\n",
    "\n",
    "        # map linear\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        if self.verbose: print('flattened:', x.shape)\n",
    "\n",
    "        # map linear\n",
    "        x = self.enc_final_linear(x)\n",
    "        if self.verbose: print('final linear:', x.shape)\n",
    "\n",
    "        mu, logvar = x[:, :256], x[:, 256:]\n",
    "        # resample\n",
    "        std = logvar.exp().pow(0.5)\n",
    "        dist = torch.distributions.Normal(mu, std)\n",
    "        latent = dist.rsample()\n",
    "\n",
    "        if self.verbose: print('latent:', latent.shape)\n",
    "        latentdim = torch.prod(torch.tensor(latent.shape[1:]))\n",
    "        if self.verbose: print('latentdim:', latentdim)\n",
    "        return latent, lengths, mu, logvar\n",
    "    \n",
    "    \n",
    "    def decode(self, z: Tensor, lengths: List[int]):\n",
    "        if self.verbose: print('DECODING')\n",
    "        mask = lengths_to_mask(lengths, z.device, self.seq_len)\n",
    "        bs, nframes = mask.shape\n",
    "        if self.verbose: print('batch size:', bs, 'nframes:', nframes, 'z shape:', z.shape)\n",
    "\n",
    "        # map linear\n",
    "        z = self.linear_dec(z)\n",
    "        if self.verbose: print('linear:', z.shape)\n",
    "        z = z.view(bs, 1, 69, 32)\n",
    "\n",
    "        if self.verbose: print('linear:', z.shape)\n",
    "        # expand with convtranspose2d\n",
    "        z = self.transconv2d_dec(z)\n",
    "        z = self.activation(z)\n",
    "        if self.verbose: print('transconv1d:', z.shape)\n",
    "\n",
    "  \n",
    "        # map linear\n",
    "        z = z.permute(0, 2, 1, 3).flatten(start_dim=2)\n",
    "        z = self.linear_dec2(z)\n",
    "        z = self.activation(z)\n",
    "        if self.verbose: print('linear:', z.shape)\n",
    "\n",
    "        # apply transformer\n",
    "        z = self.skip_trans_dec2(z)\n",
    "        if self.verbose: print('skip trans dec2:', z.shape)\n",
    "        \n",
    "        # final layer\n",
    "        output = self.final_layer(z)\n",
    "        if self.verbose: print('final layer:', output.shape)\n",
    "        output[~mask] = 0\n",
    "        feats = output#.permute(1, 0, 2)\n",
    "        if self.verbose: print('feats:', feats.shape)\n",
    "\n",
    "        return feats\n",
    "\n",
    "device = 'cpu'\n",
    "sample = torch.randn(16, 420, 66).to(device)\n",
    "\n",
    "model = CascadingTransformerAutoEncoder(256, 8, 5, 2048, 0.1, 'relu', 420, True).to(device)\n",
    "output, mu, logvar = model(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        ...,\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1 loss: 0.009999986737966537\n",
      "v2 loss: 0.009999984875321388\n",
      "total loss: 0.009999985806643963\n"
     ]
    }
   ],
   "source": [
    "v1_pred = [.9,2.1,3.1,4.1, 0, 0, 0]\n",
    "v1_true = [1,2,3,4,0,0,0]\n",
    "\n",
    "v2_pred = [.9,2.1,3.1,4.1, 5.1, 6.1, 7.1]\n",
    "v2_true = [1,2,3,4,5,6,7]\n",
    "\n",
    "# get lengths\n",
    "lengths = [4, 7]\n",
    "\n",
    "# mse\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "v1_loss = criterion(torch.tensor(v1_pred), torch.tensor(v1_true))\n",
    "v2_loss = criterion(torch.tensor(v2_pred), torch.tensor(v2_true))\n",
    "\n",
    "# scale by lengths\n",
    "v1_loss = v1_loss / lengths[0]\n",
    "v2_loss = v2_loss / lengths[1]\n",
    "\n",
    "print('v1 loss:', v1_loss.item())\n",
    "print('v2 loss:', v2_loss.item())\n",
    "\n",
    "# total loss\n",
    "total_loss = (v1_loss + v2_loss)/2\n",
    "print('total loss:', total_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total loss: 0.009999985806643963\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class BatchSequenceMSELoss:\n",
    "    def __init__(self):\n",
    "        self.criterion = nn.MSELoss(reduction='none')  # Compute loss per element\n",
    "\n",
    "    def compute_loss(self, preds, trues, lengths):\n",
    "        # Ensure inputs are tensors\n",
    "        preds = torch.tensor(preds, dtype=torch.float32)\n",
    "        trues = torch.tensor(trues, dtype=torch.float32)\n",
    "        \n",
    "        # Compute MSE loss per element\n",
    "        losses = self.criterion(preds, trues)\n",
    "        \n",
    "        # Mask out losses beyond each sequence's length\n",
    "        mask = torch.arange(losses.size(1)).expand(len(lengths), losses.size(1)) < torch.tensor(lengths).unsqueeze(1)\n",
    "        masked_losses = losses * mask\n",
    "        \n",
    "        # Sum and normalize by the effective sequence length\n",
    "        loss_per_sequence = masked_losses.sum(dim=1) / torch.tensor(lengths, dtype=torch.float32)\n",
    "        return loss_per_sequence\n",
    "\n",
    "    def total_loss(self, predictions, targets, lengths):\n",
    "        loss_per_sequence = self.compute_loss(predictions, targets, lengths)\n",
    "        return loss_per_sequence.mean()\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class VAE_Loss(nn.Module):\n",
    "    def __init__(self, loss_weights):\n",
    "        \"\"\"\n",
    "        Initialize the CustomLoss module with a structure for loss_weights that defines\n",
    "        each loss component, its calculation method, and its weight.\n",
    "\n",
    "        Parameters:\n",
    "            loss_weights (dict): A dictionary where each key is 'name_method', and the value is weight\n",
    "        \"\"\"\n",
    "        super(VAE_Loss, self).__init__()\n",
    "        self.loss_weights = loss_weights\n",
    "           \n",
    "    def forward(self, loss_data, lengths=None):\n",
    "        \"\"\"\n",
    "        Calculate and return the custom loss based on the provided loss data and methods defined\n",
    "        in the initialization.\n",
    "\n",
    "        Parameters:\n",
    "            loss_data (dict): A dictionary with keys for each loss component (including 'mu' and 'logvar'\n",
    "                              for KL divergence) and values containing the data necessary for loss calculation.\n",
    "\n",
    "        Returns:\n",
    "            float: The total loss calculated from the sum of all components.\n",
    "            dict: A dictionary containing the calculated losses for each component and the total loss.\n",
    "            dict: loss unscaled\n",
    "        \"\"\"\n",
    "\n",
    "        total_loss = 0.0\n",
    "        losses_unscaled = {}\n",
    "        losses_scaled  = {}\n",
    "        for k, v in loss_data.items():\n",
    "            # print(k)\n",
    "            name, method = k.split('_')\n",
    "            weight = self.loss_weights.get(k)\n",
    "            # print(weight)\n",
    "            if weight in [0, None]:\n",
    "                continue\n",
    "\n",
    "            if method == 'L2':\n",
    "                losses_unscaled[k] = \n",
    "            elif method == 'L1':\n",
    "                losses_unscaled[k] = F.l1_loss(v['rec'], v['true'], reduction='mean') \n",
    "            elif method == 'KL':\n",
    "                losses_unscaled[k] = self.kl_divergence(v['mu'], v['logvar'])\n",
    "            elif method == 'BCE':\n",
    "                losses_unscaled[k] = F.binary_cross_entropy(v['rec'], v['true'], reduction='mean')\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid loss method '{method}' provided for loss component '{k}'.\")\n",
    "\n",
    "            losses_scaled[k] = weight * losses_unscaled[k]\n",
    "            total_loss += losses_scaled[k]\n",
    "\n",
    "        return total_loss, losses_scaled, losses_unscaled\n",
    "\n",
    "    def kl_divergence(self, mu, logvar):\n",
    "        \"\"\"\n",
    "        Calculate the KL divergence loss, encouraging a more compact latent space by penalizing large values of mu and sigma.\n",
    "        \n",
    "        Parameters:\n",
    "            mu (Tensor): The mean vector of the latent space distribution.\n",
    "            logvar (Tensor): The log variance vector of the latent space distribution.\n",
    "        \n",
    "        Returns:\n",
    "            Tensor: The computed KL divergence loss.\n",
    "        \"\"\"\n",
    "        return -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "loss_calculator = BatchSequenceMSELoss()\n",
    "\n",
    "# Predictions and ground truths\n",
    "predictions = [\n",
    "    [0.9, 2.1, 3.1, 4.1, 0, 0, 0],\n",
    "    [0.9, 2.1, 3.1, 4.1, 5.1, 6.1, 7.1]\n",
    "]\n",
    "targets = [\n",
    "    [1, 2, 3, 4, 0, 0, 0],\n",
    "    [1, 2, 3, 4, 5, 6, 7]\n",
    "]\n",
    "\n",
    "# Effective lengths of the sequences\n",
    "lengths = [4, 7]\n",
    "\n",
    "# Calculate total loss\n",
    "total_loss = loss_calculator.total_loss(predictions, targets, lengths)\n",
    "print('Total loss:', total_loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 75\u001b[0m\n\u001b[1;32m     72\u001b[0m lengths \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m7\u001b[39m])\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Calculate loss\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m total_loss, losses_scaled, losses_unscaled \u001b[38;5;241m=\u001b[39m \u001b[43mvae_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlengths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal Loss:\u001b[39m\u001b[38;5;124m'\u001b[39m, total_loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/anaconda3/envs/t2mENV/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[26], line 38\u001b[0m, in \u001b[0;36mVAE_Loss.forward\u001b[0;34m(self, loss_data, lengths)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL2\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 38\u001b[0m     l \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msequence_mse_loss(v[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrec\u001b[39m\u001b[38;5;124m'\u001b[39m], v[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m'\u001b[39m], lengths) \u001b[38;5;28;01mif\u001b[39;00m lengths \u001b[38;5;28;01melse\u001b[39;00m F\u001b[38;5;241m.\u001b[39mmse_loss(v[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrec\u001b[39m\u001b[38;5;124m'\u001b[39m], v[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m'\u001b[39m], reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     39\u001b[0m     losses_unscaled[k] \u001b[38;5;241m=\u001b[39m l \u001b[38;5;241m/\u001b[39m lengths\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;28;01mif\u001b[39;00m lengths \u001b[38;5;28;01melse\u001b[39;00m F\u001b[38;5;241m.\u001b[39mmse_loss(v[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrec\u001b[39m\u001b[38;5;124m'\u001b[39m], v[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m'\u001b[39m], reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL1\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class BatchSequenceMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.criterion = nn.MSELoss(reduction='none')  # Compute loss per element\n",
    "\n",
    "    def forward(self, preds, trues, lengths):\n",
    "        preds = torch.tensor(preds, dtype=torch.float32)\n",
    "        trues = torch.tensor(trues, dtype=torch.float32)\n",
    "        \n",
    "        losses = self.criterion(preds, trues)\n",
    "        mask = torch.arange(losses.size(1)).expand(len(lengths), losses.size(1)) < torch.tensor(lengths).unsqueeze(1)\n",
    "        masked_losses = losses * mask\n",
    "        \n",
    "        loss_per_sequence = masked_losses.sum(dim=1) / torch.tensor(lengths, dtype=torch.float32)\n",
    "        return loss_per_sequence.sum()\n",
    "\n",
    "class VAE_Loss(nn.Module):\n",
    "    def __init__(self, loss_weights):\n",
    "        super(VAE_Loss, self).__init__()\n",
    "        self.loss_weights = loss_weights\n",
    "        self.sequence_mse_loss = BatchSequenceMSELoss()  # integrate the sequence MSE loss here\n",
    "\n",
    "    def forward(self, loss_data, lengths=None):\n",
    "        total_loss = 0.0\n",
    "        losses_unscaled = {}\n",
    "        losses_scaled = {}\n",
    "        for k, v in loss_data.items():\n",
    "            name, method = k.split('_')\n",
    "            weight = self.loss_weights.get(k, 0)\n",
    "            if weight == 0:\n",
    "                continue\n",
    "\n",
    "            if method == 'L2':\n",
    "                if lengths is not None:\n",
    "                    l = self.sequence_mse_loss(v['rec'], v['true'], lengths)# if lengths else F.mse_loss(v['rec'], v['true'], reduction='sum')\n",
    "                    losses_unscaled[k] = l / lengths.sum()# if lengths else F.mse_loss(v['rec'], v['true'], reduction='mean')\n",
    "                else:\n",
    "                    losses_unscaled[k] = F.mse_loss(v['rec'], v['true'], reduction='mean')\n",
    "                    \n",
    "            elif method == 'L1':\n",
    "                losses_unscaled[k] = F.l1_loss(v['rec'], v['true'], reduction='mean')\n",
    "            elif method == 'KL':\n",
    "                losses_unscaled[k] = self.kl_divergence(v['mu'], v['logvar'])\n",
    "            elif method == 'BCE':\n",
    "                losses_unscaled[k] = F.binary_cross_entropy(v['rec'], v['true'], reduction='mean')\n",
    "            else:\n",
    "                raise ValueError(f\"Invalid loss method '{method}' provided for loss component '{k}'.\")\n",
    "\n",
    "            losses_scaled[k] = weight * losses_unscaled[k]\n",
    "            total_loss += losses_scaled[k]\n",
    "\n",
    "        return total_loss, losses_scaled, losses_unscaled\n",
    "\n",
    "    def kl_divergence(self, mu, logvar):\n",
    "        return -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "# Example of setting up the VAE_Loss\n",
    "loss_weights = {\n",
    "    'reconstruction_L2': 1.0,\n",
    "    'kl_KL': 0.5  # Example weights\n",
    "}\n",
    "\n",
    "vae_loss = VAE_Loss(loss_weights)\n",
    "\n",
    "# Example data\n",
    "loss_data = {\n",
    "    'reconstruction_L2': {'rec': [[0.9, 2.1, 3.1, 4.1, 0, 0, 0], [0.9, 2.1, 3.1, 4.1, 5.1, 6.1, 7.1]],\n",
    "                          'true': [[1, 2, 3, 4, 0, 0, 0], [1, 2, 3, 4, 5, 6, 7]]},\n",
    "    'kl_KL': {'mu': torch.zeros(10, 32), 'logvar': torch.zeros(10, 32)}\n",
    "}\n",
    "\n",
    "lengths = torch.tensor([4, 7])\n",
    "\n",
    "# Calculate loss\n",
    "total_loss, losses_scaled, losses_unscaled = vae_loss(loss_data, lengths)\n",
    "print('Total Loss:', total_loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 8, 60, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t2mENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
