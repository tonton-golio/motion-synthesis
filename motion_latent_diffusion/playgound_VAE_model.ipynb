{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENCODING\n",
      "batch size: 32 nframes: 420 nfeats: 66\n",
      "skel_enc: torch.Size([32, 420, 256])\n",
      "skip trans enc: torch.Size([32, 420, 256])\n",
      "conv2d: torch.Size([32, 8, 209, 1])\n",
      "skip trans enc2: torch.Size([32, 209, 8])\n",
      "conv2d2: torch.Size([32, 69, 8])\n",
      "latent: torch.Size([32, 69, 4])\n",
      "latentdim: tensor(276)\n",
      "DECODING\n",
      "batch size: 32 nframes: 420\n",
      "transconv2d: torch.Size([32, 69, 4])\n",
      "transconv2d: torch.Size([32, 8, 209, 8])\n",
      "skip trans dec: torch.Size([32, 209, 64])\n",
      "transconv2d2: torch.Size([32, 1, 420, 255])\n",
      "skip trans dec2: torch.Size([32, 420, 255])\n",
      "final layer: torch.Size([32, 420, 66])\n",
      "feats: torch.Size([420, 32, 66])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from utils import (\n",
    "    plot_3d_motion_frames_multiple,\n",
    "    plot_3d_motion_animation,\n",
    "    plot_3d_motion_frames_multiple,\n",
    "    activation_dict,\n",
    ")\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from modules.loss import VAE_Loss\n",
    "\n",
    "from torch import Tensor\n",
    "from typing import List, Optional\n",
    "import copy\n",
    "\n",
    "def lengths_to_mask(lengths: List[int],\n",
    "                    device: torch.device,\n",
    "                    max_len: int = None) -> Tensor:\n",
    "    \"\"\"\n",
    "    Provides a mask, of length max_len or the longest element in lengths. With True for the elements less than the length for each length in lengths.\n",
    "    \"\"\"\n",
    "    lengths = torch.tensor(lengths, device=device)\n",
    "    max_len = max_len if max_len else max(lengths)\n",
    "    mask = torch.arange(max_len, device=device).expand(len(lengths), max_len) < lengths.unsqueeze(1)\n",
    "    return mask\n",
    "\n",
    "def _get_clones(module, N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n",
    "\n",
    "def _get_clone(module):\n",
    "    return copy.deepcopy(module)\n",
    "\n",
    "class SkipTransformerEncoder(nn.Module):\n",
    "    def __init__(self, encoder_layer, num_layers, norm=None, d_model=256):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        self.norm = norm\n",
    "\n",
    "        assert num_layers % 2 == 1\n",
    "\n",
    "        num_block = (num_layers-1)//2\n",
    "        self.input_blocks = _get_clones(encoder_layer, num_block)\n",
    "        self.middle_block = _get_clone(encoder_layer)\n",
    "        self.output_blocks = _get_clones(encoder_layer, num_block)\n",
    "        self.linear_blocks = _get_clones(nn.Linear(2*self.d_model, self.d_model), num_block)\n",
    "\n",
    "        self._reset_parameters()\n",
    "\n",
    "    def _reset_parameters(self):\n",
    "        for p in self.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "\n",
    "    def forward(self, src,\n",
    "                mask: Optional[Tensor] = None,\n",
    "                src_key_padding_mask: Optional[Tensor] = None,\n",
    "                pos: Optional[Tensor] = None):\n",
    "        x = src\n",
    "\n",
    "        xs = []\n",
    "        for module in self.input_blocks:\n",
    "            x = module(x, src_mask=mask,\n",
    "                           src_key_padding_mask=src_key_padding_mask)\n",
    "            xs.append(x)\n",
    "\n",
    "        x = self.middle_block(x, src_mask=mask,\n",
    "                           src_key_padding_mask=src_key_padding_mask)\n",
    "\n",
    "        for (module, linear) in zip(self.output_blocks, self.linear_blocks):\n",
    "            x = torch.cat([x, xs.pop()], dim=-1)\n",
    "            x = linear(x)\n",
    "            x = module(x, src_mask=mask,\n",
    "                           src_key_padding_mask=src_key_padding_mask, \n",
    "                           )\n",
    "\n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "        return x\n",
    "\n",
    "class CascadingTransformerAutoEncoder(nn.Module):\n",
    "    def __init__(self, d_model, nhead, num_layers, dim_feedforward=2048, dropout=0.1, activation='relu', seq_len=120, verbose=False):\n",
    "        super(CascadingTransformerAutoEncoder, self).__init__()\n",
    "        self.latent_size = 1   # 1 for single timestep\n",
    "        self.latent_dim = d_model # 256\n",
    "        self.seq_len = seq_len\n",
    "        self.verbose = verbose\n",
    "        self.conv1_out_channels = 8\n",
    "        \n",
    "        # ENCODER\n",
    "        self.skel_enc = nn.Linear(66, d_model)\n",
    "    \n",
    "        self.skip_trans_enc = SkipTransformerEncoder(\n",
    "            encoder_layer= nn.TransformerEncoderLayer(\n",
    "                d_model=256, nhead=8, dim_feedforward=1024, \n",
    "                dropout=0.1, activation='relu', \n",
    "                norm_first=False, batch_first=True),\n",
    "            num_layers=3,\n",
    "            norm=nn.LayerNorm(256),\n",
    "            d_model=256\n",
    "        )\n",
    "\n",
    "        self.conv2d_enc = nn.Conv2d(\n",
    "                            in_channels=1,\n",
    "                            out_channels=self.conv1_out_channels,\n",
    "                            kernel_size=(3, 256),\n",
    "                            stride=(2, 1),\n",
    "                            padding=(0, 0))\n",
    "        \n",
    "        self.skip_trans_enc2 = SkipTransformerEncoder(\n",
    "            encoder_layer= nn.TransformerEncoderLayer(\n",
    "                d_model=self.conv1_out_channels, nhead=8, dim_feedforward=64,\n",
    "                dropout=0.1, activation='relu',\n",
    "                norm_first=False, batch_first=True),\n",
    "            num_layers=3,\n",
    "            norm=nn.LayerNorm(self.conv1_out_channels),\n",
    "            d_model=self.conv1_out_channels\n",
    "        )\n",
    "\n",
    "        self.conv2d_enc2 = nn.Conv2d(\n",
    "                            in_channels=1,\n",
    "                            out_channels=1,\n",
    "                            kernel_size=(4, 1),\n",
    "                            stride=(3, 1),\n",
    "                            padding=(0, 0))\n",
    "        \n",
    "        # DECODER\n",
    "        self.transconv2d_dec = nn.ConvTranspose2d(\n",
    "                            in_channels=1,\n",
    "                            out_channels=8,\n",
    "                            kernel_size=(4, 1),\n",
    "                            stride=(3, 2),\n",
    "                            padding=(0, 0), \n",
    "                            output_padding=(1, 1))\n",
    "        \n",
    "        self.skip_trans_dec = SkipTransformerEncoder(\n",
    "            encoder_layer= nn.TransformerEncoderLayer(\n",
    "                d_model=64, nhead=4, dim_feedforward=256,\n",
    "                dropout=dropout, activation=activation,\n",
    "                norm_first=False, batch_first=True),\n",
    "            num_layers=3,\n",
    "            norm=nn.LayerNorm(64),\n",
    "            d_model=64\n",
    "        )\n",
    "\n",
    "        self.transconv2d_dec2 = nn.ConvTranspose2d(\n",
    "                            in_channels=1,\n",
    "                            out_channels=1,\n",
    "                            kernel_size=(3, 64),\n",
    "                            stride=(2, 3),\n",
    "                            padding=(0, 0), \n",
    "                            output_padding=(1, 2))\n",
    "        \n",
    "        self.skip_trans_dec2 = SkipTransformerEncoder(\n",
    "            encoder_layer= nn.TransformerEncoderLayer(\n",
    "                d_model=255, nhead=15, dim_feedforward=1024,\n",
    "                dropout=0.1, activation='relu',\n",
    "                norm_first=False, batch_first=True),\n",
    "            num_layers=3,\n",
    "            norm=nn.LayerNorm(255),\n",
    "            d_model=255\n",
    "        )\n",
    "        \n",
    "        self.final_layer = nn.Linear(255, 66)\n",
    "        \n",
    "    def forward(self, src: Tensor):\n",
    "        z, lengths, mu, logvar = self.encode(src)\n",
    "        # mu, logvar = dist[:1], dist[1:]\n",
    "        # z = self.reparameterize(mu, logvar)\n",
    "        output, mask = self.decode(z, lengths)\n",
    "        return output, mu, logvar\n",
    "\n",
    "    def encode(self, src):\n",
    "        # get lengths\n",
    "        lengths = [len(feature) for feature in src]\n",
    "\n",
    "\n",
    "        if self.verbose: print('ENCODING')\n",
    "        # get shapes\n",
    "        bs, nframes, nfeats = src.shape\n",
    "        if self.verbose: print('batch size:', bs, 'nframes:', nframes, 'nfeats:', nfeats)\n",
    "\n",
    "        # skeletal embedding\n",
    "        x = self.skel_enc(src)\n",
    "        if self.verbose: print('skel_enc:', x.shape)\n",
    "\n",
    "        # pass through transformerencoder with skip connections\n",
    "        x = self.skip_trans_enc(x)\n",
    "        if self.verbose: print('skip trans enc:', x.shape)\n",
    "\n",
    "        # make small with conv2d\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.conv2d_enc(x)\n",
    "        if self.verbose: print('conv2d:', x.shape)\n",
    "\n",
    "        # pass through transformerencoder with skip connections\n",
    "        x = x.squeeze(-1).permute(0, 2, 1)\n",
    "        # x = self.skip_trans_enc2(x)\n",
    "        if self.verbose: print('skip trans enc2:', x.shape)\n",
    "\n",
    "        # make small with conv2d\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.conv2d_enc2(x).squeeze(1)\n",
    "        if self.verbose: print('conv2d2:', x.shape)\n",
    "\n",
    "        mu, logvar = x[:, :, :4], x[:, :, 4:]\n",
    "        # resample\n",
    "        std = logvar.exp().pow(0.5)\n",
    "        dist = torch.distributions.Normal(mu, std)\n",
    "        latent = dist.rsample()\n",
    "\n",
    "        if self.verbose: print('latent:', latent.shape)\n",
    "        latentdim = torch.prod(torch.tensor(latent.shape[1:]))\n",
    "        if self.verbose: print('latentdim:', latentdim)\n",
    "        return latent, lengths, mu, logvar\n",
    "    \n",
    "    \n",
    "    def decode(self, z: Tensor, lengths: List[int]):\n",
    "        if self.verbose: print('DECODING')\n",
    "        mask = lengths_to_mask(lengths, z.device, self.seq_len)\n",
    "        bs, nframes = mask.shape\n",
    "        if self.verbose: print('batch size:', bs, 'nframes:', nframes)\n",
    "\n",
    "        # expand with convtranspose2d\n",
    "        if self.verbose: print('transconv2d:', z.shape)\n",
    "        z = z.unsqueeze(1)\n",
    "        z = self.transconv2d_dec(z)\n",
    "        if self.verbose: print('transconv2d:', z.shape)\n",
    "\n",
    "        # apply transformer\n",
    "        z = z.permute(0, 2, 1, 3)\n",
    "        z = z.reshape(z.shape[0], z.shape[1], -1)\n",
    "        z = self.skip_trans_dec(z)\n",
    "        if self.verbose: print('skip trans dec:', z.shape)\n",
    "\n",
    "        # expand with convtranspose2d\n",
    "        z = z.unsqueeze(1)\n",
    "        z = self.transconv2d_dec2(z)\n",
    "        if self.verbose: print('transconv2d2:', z.shape)\n",
    "\n",
    "        # apply transformer\n",
    "        z = z.squeeze(1)\n",
    "        z = self.skip_trans_dec2(z)\n",
    "        if self.verbose: print('skip trans dec2:', z.shape)\n",
    "        \n",
    "        # final layer\n",
    "        output = self.final_layer(z)\n",
    "        if self.verbose: print('final layer:', output.shape)\n",
    "        output[~mask] = 0\n",
    "        feats = output.permute(1, 0, 2)\n",
    "        if self.verbose: print('feats:', feats.shape)\n",
    "\n",
    "        return feats, mask\n",
    "    \n",
    "\n",
    "sample = torch.randn(32, 420, 66)\n",
    "\n",
    "model = CascadingTransformerAutoEncoder(256, 8, 5, 2048, 0.1, 'relu', 420, True)\n",
    "output, mu, logvar = model(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        ...,\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 8, 60, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t2mENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
